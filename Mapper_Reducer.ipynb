{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mapper_Reducer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAS76kd7ZubF",
        "colab_type": "text"
      },
      "source": [
        "# **MAPPER REDUCER IMPLEMENTATION FROM SCRATCH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCjAUG8DZ35O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46e68164-949d-4bf7-d061-eed333bf0f31"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9rR6tL_aR1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "757efdcc-64dc-4321-bddb-bc68d4956225"
      },
      "source": [
        "%cd /content/drive/My Drive/Mapper_Reducer\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Mapper_Reducer\n",
            "textdoc.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEeVi-C8ZLBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import libraries\n",
        "import os           #For reading file\n",
        "import re           #sub - For removing numbers\n",
        "import string       #For string operations \n",
        "import pandas as pd #For data frame operations\n",
        "import numpy  as np #For transformation operations"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbwDFsPUZSZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Opening teh input file for reading\n",
        "fileread = open(\"textdoc.txt\", \"r\", encoding=\"utf8\")\n",
        "file = fileread.read()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCfXt8ZBZYGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Cleaning Function\n",
        "\n",
        "def data_cleaning(file):\n",
        "  #1. Removing Punctuations\n",
        "  file = file.translate(str.maketrans('', '', string.punctuation))\n",
        "  \n",
        "  #2. Removing Apostrophe\n",
        "  file = file.replace(\"'\", \"\")\n",
        "  \n",
        "  #3. Converting all words to Lowercase\n",
        "  file = file.lower()\n",
        "\n",
        "  #3. Removing Numbers\n",
        "  file_cleaned      = re.sub(r'\\d+', '', file)\n",
        "  \n",
        "  return file_cleaned"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BK5FUAhc5b5",
        "colab_type": "text"
      },
      "source": [
        "**MAPPER FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-60vkrEwZc2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "8b8a8681-037e-40c5-8e3d-f307c28bd41c"
      },
      "source": [
        "#Final Operations\n",
        "file_cleaned = data_cleaning(file)\n",
        "\n",
        "#To pass the previous chunk output to this chunk everytime it is executed\n",
        "file = file_cleaned\n",
        "\n",
        "#For splitting the file in different lines\n",
        "file = file.splitlines()\n",
        "#For removing WhiteSpaces\n",
        "file = filter(lambda x: not re.match(r'^\\s*$', x), file)\n",
        "\n",
        "file = pd.DataFrame(file)\n",
        "#Splitting the file into 2 parts - file1 containing first 5000 lines and file2 containing the rest\n",
        "file1 = file[:5000]\n",
        "file2 = file[5000:]\n",
        "\n",
        "file1_map = file1\n",
        "file2_map = file2\n",
        "\n",
        "words1 = []\n",
        "for i in range(len(file1_map)):\n",
        "  line = file1_map.iloc[i]\n",
        "  string = line.to_string()\n",
        "  string = string[1:]\n",
        "  words = string.split()\n",
        "  words1.extend(words)      #Used here to append multiple lists into one list\n",
        "\n",
        "words2 = []\n",
        "for i in range(len(file2_map)):\n",
        "  line = file2_map.iloc[i]\n",
        "  string = line.to_string()\n",
        "  string = string[1:]\n",
        "  words = string.split()\n",
        "  words2.extend(words)      #Used here to append multiple lists into one list\n",
        "\n",
        "words1_map = words1\n",
        "words2_map = words2\n",
        "\n",
        "words_mapper = pd.DataFrame(words1_map)\n",
        "words_mapper[1] = '1'\n",
        "words_mapper.columns = ['Key', 'Value']\n",
        "print (words_mapper[1:9].to_string(index=False, header=None))\n",
        "#Printing below are some of the Key value pairs obtained after the Mapper function -"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       and  1\n",
            " prejudice  1\n",
            "        by  1\n",
            "      jane  1\n",
            "    austen  1\n",
            "   chapter  1\n",
            "        it  1\n",
            "        is  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osG71bMUc8Hh",
        "colab_type": "text"
      },
      "source": [
        "**REDUCER FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEAjbusZctMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "304f2c1c-aec8-4cee-efa4-1bec4f3d4cb2"
      },
      "source": [
        "words_reducer = words_mapper\n",
        "words_reducer = words_reducer.groupby('Key')\n",
        "#print(words_mapper)\n",
        "print(words_reducer.agg(np.count_nonzero))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Value\n",
            "Key               \n",
            "...            824\n",
            "a              672\n",
            "a...            89\n",
            "ab...            3\n",
            "abatement        1\n",
            "...            ...\n",
            "yours...         1\n",
            "yourself        14\n",
            "yourself...      1\n",
            "yourselfand      1\n",
            "youth            1\n",
            "\n",
            "[5309 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45aTyIBrcw7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Closing the file connection\n",
        "fileread.close()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wYcbvGTbEFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e768634e-570a-4c43-f3e9-6364dfc47d99"
      },
      "source": [
        "words_reducer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f152bbcdfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}